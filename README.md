# Basic-ML-Algorithm-From-Scratch
This repository contains implementations of core machine learning algorithms from scratch, without relying on prebuilt Python libraries like scikit-learn. Each algorithm is coded from first principles to demonstrate a clear understanding of their inner workings. The algorithms included are:

## Gradient Descent: 
A simple yet powerful optimization technique used for minimizing functions, typically used in linear and logistic regression models.
## K-Nearest Neighbors (KNN): 
A classification algorithm that assigns labels based on the majority class of the nearest neighbors.
## Naive Bayes: 
A probabilistic classifier based on Bayes' Theorem, assuming independence between features.

These implementations are built purely with base Python libraries like numpy for matrix operations, focusing on learning basics and transparency rather than performance.
